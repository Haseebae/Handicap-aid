{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyautogui\n",
    "import time\n",
    "\n",
    "# media pipe dependencies\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from scipy.spatial import distance as dist\n",
    "from datetime import datetime\n",
    "\n",
    "# audio file dependencies\n",
    "import speech_recognition as sr\n",
    "import pyttsx3\n",
    "import pyperclip"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "media pipe variables and functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "\n",
    "drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "morse = {\n",
    "  \".-\": 'a',\n",
    "  \"-...\": 'b',\n",
    "  \"-.-.\": 'c',\n",
    "  \"-..\": 'd',\n",
    "  \".\": 'e',\n",
    "  \"..-.\": 'f',\n",
    "  \"--.\": 'g',\n",
    "  \"....\": 'h',\n",
    "  \"..\": 'i',\n",
    "  \".---\": 'j',\n",
    "  \"-.-\": 'k',\n",
    "  \".-..\": 'l',\n",
    "  \"--\": 'm',\n",
    "  \"-.\": 'n',\n",
    "  \"---\": 'o',\n",
    "  \".--.\": 'p',\n",
    "  \"--.-\": 'q',\n",
    "  \".-.\": 'r',\n",
    "  \"...\": 's',\n",
    "  \"-\": 't',\n",
    "  \"..-\": 'u',\n",
    "  \"...-\": 'v',\n",
    "  \".--\": 'w',\n",
    "  \"-..-\": 'x',\n",
    "  \"-.--\": 'y',\n",
    "  \"--..\": 'z',\n",
    "  \".----\": '1',\n",
    "  \"..---\": '2',\n",
    "  \"...--\": '3',\n",
    "  \"....-\": '4',\n",
    "  \".....\": '5',\n",
    "  \"-....\": '6',\n",
    "  \"--...\": '7',\n",
    "  \"---..\": '8',\n",
    "  \"----.\": '9',\n",
    "  \"-----\": '0',\n",
    "  \".-.-.-\": '.',\n",
    "  \"--..--\": ',',\n",
    "  \"---...\": ';',\n",
    "  \".----.\": \"'\",\n",
    "  \".----.-\": '`',\n",
    "  \"-....-\": '-',\n",
    "  \"-...-\": '=',\n",
    "  \"-..-.\": '/',\n",
    "  \"-..-.-\": '\\\\',\n",
    "  \"----.-\": '[',\n",
    "  \"------\": ']',\n",
    "  \".-.-\": 'tab',\n",
    "  \"space\": \"space\",\n",
    "  \"enter\": \"enter\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAMERA = 0 # Usually 0, depends on input device(s)\n",
    "\n",
    "# Optionally record the video feed to a timestamped AVI in the current directory\n",
    "RECORDING = False\n",
    "FPS = 10\n",
    "RECORDING_FILENAME = str(datetime.now()).replace('.','').replace(':','') + '.avi'\n",
    "\n",
    "FACE_TILT = .5\n",
    "\n",
    "EYE_BLINK_HEIGHT = .15\n",
    "EYE_SQUINT_HEIGHT = .18\n",
    "EYE_OPEN_HEIGHT = .25\n",
    "EYE_BUGGED_HEIGHT = .7\n",
    "\n",
    "MOUTH_OPEN_HEIGHT = .2\n",
    "MOUTH_OPEN_SHORT_FRAMES = 1\n",
    "MOUTH_OPEN_LONG_FRAMES = 4\n",
    "MOUTH_CLOSED_FRAMES = 1\n",
    "\n",
    "MOUTH_FROWN = .006\n",
    "MOUTH_NOSE_SCRUNCH = .09\n",
    "MOUTH_SNARL = .1\n",
    "MOUTH_DUCKFACE = 1.6\n",
    "\n",
    "BROW_RAISE_LEFT = .0028\n",
    "BROW_RAISE_RIGHT = .025\n",
    "BROWS_RAISE = .19\n",
    "\n",
    "WAIT_FRAMES = 6\n",
    "\n",
    "\n",
    "blinking = False\n",
    "blink_count = 0\n",
    "blinking_frames = 0\n",
    "\n",
    "squinting = False\n",
    "squinting_frames = 0\n",
    "\n",
    "bugeyed = False\n",
    "bugeyed_frames = 0\n",
    "\n",
    "winkedR = False\n",
    "winkedR_frames = 0\n",
    "\n",
    "winkedL = False\n",
    "winkedL_frames = 0\n",
    "\n",
    "mouth_open = False\n",
    "mouth_open_frames = 0\n",
    "mouth_closed_frames = 0\n",
    "\n",
    "mouth_scrunched = False\n",
    "mouth_scrunched_count = 0\n",
    "mouth_scrunched_frames = 0\n",
    "\n",
    "duckfacing = False\n",
    "\n",
    "brows_raised = False\n",
    "brows_raised_count = 0\n",
    "brows_raised_frames = 0\n",
    "\n",
    "command_on = False\n",
    "control_on = False\n",
    "shift_on = False\n",
    "\n",
    "current_morse = ''\n",
    "last_typed = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_and_remember():\n",
    "  global current_morse, last_typed\n",
    "  keys = []\n",
    "\n",
    "  if command_on:\n",
    "    keys.append('command')\n",
    "  if control_on:\n",
    "    keys.append('control')\n",
    "  if shift_on:\n",
    "    keys.append('shift')\n",
    "\n",
    "  letter = morse.get(current_morse, '')\n",
    "  if len(letter):\n",
    "    keys.append(letter)\n",
    "  current_morse = ''\n",
    "\n",
    "  keystring = '+'.join(keys)\n",
    "  if len(keystring):\n",
    "    print(\"keys:\", keystring)\n",
    "    #keyboard.press_and_release(keystring)\n",
    "    last_typed = keystring\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect_ratio(top, bottom, right, left):\n",
    "  height = dist.euclidean([top.x, top.y], [bottom.x, bottom.y])\n",
    "  width = dist.euclidean([right.x, right.y], [left.x, left.y])\n",
    "  return height / width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeout_double(state, frames):\n",
    "  if state:\n",
    "    frames += 1\n",
    "  if frames > WAIT_FRAMES:\n",
    "    frames = 0\n",
    "    state = False\n",
    "  return state, frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_frame(image, face_landmarks):\n",
    "  mp_drawing.draw_landmarks(\n",
    "      image=image,\n",
    "      landmark_list=face_landmarks,\n",
    "      connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "      landmark_drawing_spec=None,\n",
    "      connection_drawing_spec=mp_drawing_styles\n",
    "      .get_default_face_mesh_tesselation_style())\n",
    "  mp_drawing.draw_landmarks(\n",
    "      image=image,\n",
    "      landmark_list=face_landmarks,\n",
    "      connections=mp_face_mesh.FACEMESH_CONTOURS,\n",
    "      landmark_drawing_spec=None,\n",
    "      connection_drawing_spec=mp_drawing_styles\n",
    "      .get_default_face_mesh_contours_style())\n",
    "  mp_drawing.draw_landmarks(\n",
    "      image=image,\n",
    "      landmark_list=face_landmarks,\n",
    "      connections=mp_face_mesh.FACEMESH_IRISES,\n",
    "      landmark_drawing_spec=None,\n",
    "      connection_drawing_spec=mp_drawing_styles\n",
    "      .get_default_face_mesh_iris_connections_style())\n",
    "  frame = cv2.flip(image, 1) # Flip image horizontally\n",
    "  # Add current Morse code as supertitle\n",
    "  cv2.putText(frame, current_morse, (620, 30),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "  cv2.imshow('face', frame)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "speech to text dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SpeakText(command):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.say(command)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "parrot = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(): \n",
    "    spoken_text = []\n",
    "\n",
    "    while True:\n",
    "        with sr.Microphone() as source2:\n",
    "            r.adjust_for_ambient_noise(source2, duration = 0.5)\n",
    "            audio2 = r.listen(source2)\n",
    "            try:\n",
    "                MyText = r.recognize_google(audio2)\n",
    "                MyText = MyText.lower()\n",
    "                if MyText.endswith('terminate'):\n",
    "                    print(\"Stopping...\")\n",
    "                    words = MyText.lower().split()\n",
    "                    words.pop()\n",
    "                    new_text = \" \".join(words)\n",
    "                    print(\"parrot says : \", new_text)\n",
    "                    spoken_text.append(new_text)\n",
    "                    pyperclip.copy(new_text)\n",
    "                    time.sleep(3)\n",
    "                    pyautogui.hotkey('command', 'v')\n",
    "                    break\n",
    "                print(\"parrot says : \", MyText)\n",
    "                spoken_text.append(MyText)\n",
    "                pyperclip.copy(MyText)\n",
    "                time.sleep(3)\n",
    "                pyautogui.hotkey('command', 'v')\n",
    "\n",
    "            except sr.UnknownValueError:\n",
    "                print(\"Could not understand audio, please try again.\")\n",
    "            except sr.RequestError as e:\n",
    "                print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blink 1\n",
      "mouth open 0.2540744589158107\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.66399163,\n",
      "                           'transcript': 'open my mouth hello 10 minut as '\n",
      "                                         'whole'},\n",
      "                       {'transcript': 'open my mouth hello 10 minut as hole'},\n",
      "                       {'transcript': 'open my mouth hello cabinet as hole'},\n",
      "                       {'transcript': 'open my mouth hello 10 minute as hole'},\n",
      "                       {'transcript': 'open my mouth hello cabinet hole'}],\n",
      "    'final': True}\n",
      "parrot says :  open my mouth hello 10 minut as whole\n",
      "result2:\n",
      "[]\n",
      "Could not understand audio, please try again.\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.69034266,\n",
      "                           'transcript': 'open my mouth hello 10 minutes as '\n",
      "                                         'more'},\n",
      "                       {'transcript': 'open my mouth hello 10 minut asthma'},\n",
      "                       {'transcript': 'open my mouth hello 10 minut azmoun'},\n",
      "                       {'transcript': 'open my mouth hello 10 minutes as home'},\n",
      "                       {   'transcript': 'open my mouth hello 10 minutes as '\n",
      "                                         'moon'}],\n",
      "    'final': True}\n",
      "parrot says :  open my mouth hello 10 minutes as more\n",
      "result2:\n",
      "{   'alternative': [   {'confidence': 0.51122111, 'transcript': 'TubeMate'},\n",
      "                       {'transcript': 'vidmate'},\n",
      "                       {'transcript': '10 minute'},\n",
      "                       {'transcript': '10 minut'},\n",
      "                       {'transcript': '10 mate'}],\n",
      "    'final': True}\n",
      "parrot says :  tubemate\n",
      "result2:\n",
      "{   'alternative': [   {'confidence': 0.92995489, 'transcript': 'image'},\n",
      "                       {'transcript': 'xximage'},\n",
      "                       {'transcript': 'vidmate'},\n",
      "                       {'transcript': 'images'}],\n",
      "    'final': True}\n",
      "parrot says :  image\n",
      "result2:\n",
      "{   'alternative': [   {   'confidence': 0.4606947,\n",
      "                           'transcript': 'Indian stick minut'},\n",
      "                       {'transcript': 'Indian state minut'},\n",
      "                       {'transcript': 'Indian stick minute'},\n",
      "                       {'transcript': 'Indian state minute'},\n",
      "                       {'transcript': 'Indian state'}],\n",
      "    'final': True}\n",
      "parrot says :  indian stick minut\n",
      "result2:\n",
      "[]\n",
      "Could not understand audio, please try again.\n",
      "result2:\n",
      "{   'alternative': [   {'confidence': 0.59307128, 'transcript': 'audio system'},\n",
      "                       {'transcript': 'audio'},\n",
      "                       {'transcript': 'audio phrases mother'},\n",
      "                       {'transcript': 'audio phrases'},\n",
      "                       {'transcript': 'audio recent mother'}],\n",
      "    'final': True}\n",
      "parrot says :  audio system\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/haseeb/Code/ineuronhackathon/main.ipynb Cell 16\u001b[0m in \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m \u001b[39mif\u001b[39;00m mouth_open:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=105'>106</a>\u001b[0m   \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mmouth open\u001b[39m\u001b[39m\"\u001b[39m, mouth_inner_ar)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m   get_audio()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m draw_frame(image, face_landmarks)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m \u001b[39mif\u001b[39;00m RECORDING:\n",
      "\u001b[1;32m/Users/haseeb/Code/ineuronhackathon/main.ipynb Cell 16\u001b[0m in \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwith\u001b[39;00m sr\u001b[39m.\u001b[39mMicrophone() \u001b[39mas\u001b[39;00m source2:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     r\u001b[39m.\u001b[39madjust_for_ambient_noise(source2, duration \u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     audio2 \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mlisten(source2)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/haseeb/Code/ineuronhackathon/main.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         MyText \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mrecognize_google(audio2)\n",
      "File \u001b[0;32m~/anaconda3/envs/DS/lib/python3.10/site-packages/speech_recognition/__init__.py:709\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[39mif\u001b[39;00m phrase_time_limit \u001b[39mand\u001b[39;00m elapsed_time \u001b[39m-\u001b[39m phrase_start_time \u001b[39m>\u001b[39m phrase_time_limit:\n\u001b[1;32m    707\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m buffer \u001b[39m=\u001b[39m source\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mread(source\u001b[39m.\u001b[39;49mCHUNK)\n\u001b[1;32m    710\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(buffer) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m: \u001b[39mbreak\u001b[39;00m  \u001b[39m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    711\u001b[0m frames\u001b[39m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m~/anaconda3/envs/DS/lib/python3.10/site-packages/speech_recognition/__init__.py:211\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread\u001b[39m(\u001b[39mself\u001b[39m, size):\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpyaudio_stream\u001b[39m.\u001b[39;49mread(size, exception_on_overflow\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/DS/lib/python3.10/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot input stream\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39;49mread_stream(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stream, num_frames,\n\u001b[1;32m    571\u001b[0m                       exception_on_overflow)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(CAMERA)\n",
    "\n",
    "# to get output video, set RECORDING to true\n",
    "if RECORDING:\n",
    "  frame_size = (int(cap.get(3)), int(cap.get(4)))\n",
    "  recording = cv2.VideoWriter(\n",
    "    RECORDING_FILENAME, cv2.VideoWriter_fourcc(*'MJPG'), FPS, frame_size)\n",
    "\n",
    "with mp_face_mesh.FaceMesh(\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5) as face_mesh:\n",
    "  while cap.isOpened():\n",
    "    success, image = cap.read()\n",
    "    if not success: break\n",
    "\n",
    "    image.flags.writeable = False\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    results = face_mesh.process(image)\n",
    "\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    if results.multi_face_landmarks and len(results.multi_face_landmarks) > 0:\n",
    "      face_landmarks = results.multi_face_landmarks[0]\n",
    "      face = face_landmarks.landmark\n",
    "\n",
    "\n",
    "      eyeR_top = face[159]\n",
    "      eyeR_bottom = face[145]\n",
    "      eyeR_inner = face[133]\n",
    "      eyeR_outer = face[33]\n",
    "      eyeR_ar = get_aspect_ratio(eyeR_top, eyeR_bottom, eyeR_outer, eyeR_inner)\n",
    "\n",
    "      eyeL_top = face[386]\n",
    "      eyeL_bottom = face[374]\n",
    "      eyeL_inner = face[362]\n",
    "      eyeL_outer = face[263]\n",
    "      eyeL_ar = get_aspect_ratio(eyeL_top, eyeL_bottom, eyeL_outer, eyeL_inner)\n",
    "      eyeA_ar = (eyeR_ar + eyeL_ar) / 2\n",
    "\n",
    "      command_on = False\n",
    "      shift_on = False\n",
    "      squinting = False\n",
    "      bugeyed = False\n",
    "      if eyeR_ar < EYE_BLINK_HEIGHT:\n",
    "        if eyeL_ar > EYE_OPEN_HEIGHT:\n",
    "          print(\"R wink\", eyeR_ar)\n",
    "          shift_on = True\n",
    "          winkedR = True\n",
    "          if winkedL and (winkedL_frames < WAIT_FRAMES):\n",
    "            print(\"ESCAPE\")\n",
    "            #keyboard.press_and_release('escape')\n",
    "            winkedL_frames = 0\n",
    "            winkedL = False\n",
    "        elif eyeR_ar < EYE_BLINK_HEIGHT:\n",
    "          if not blinking:\n",
    "            blink_count += 1\n",
    "            print(\"blink\", blink_count)\n",
    "            if duckfacing and blink_count == 2:\n",
    "              print(\"BACKSPACE\")\n",
    "              #keyboard.press_and_release(\"backspace\")\n",
    "          blinking = True\n",
    "      elif eyeL_ar < EYE_BLINK_HEIGHT and eyeR_ar > EYE_OPEN_HEIGHT:\n",
    "        print(\"L wink\", eyeL_ar)\n",
    "        command_on = True\n",
    "        winkedL = True\n",
    "        if winkedR and (winkedR_frames < WAIT_FRAMES):\n",
    "          print(\"clear Morse queue\")\n",
    "          current_morse = ''\n",
    "          winkedR_frames = 0\n",
    "          winkedR = False\n",
    "      elif eyeA_ar < EYE_SQUINT_HEIGHT:\n",
    "        squinting = True\n",
    "        squinting_frames += 1\n",
    "        if squinting_frames > WAIT_FRAMES:\n",
    "          print(\"squint\", eyeA_ar)\n",
    "          #keyboard.press_and_release(\"command+-\") # zoom out\n",
    "          squinting_frames = 0\n",
    "      elif eyeA_ar > EYE_BUGGED_HEIGHT:\n",
    "        bugeyed = True\n",
    "        bugeyed_frames += 1\n",
    "        if bugeyed_frames > WAIT_FRAMES:\n",
    "          bugeyed_frames = 0\n",
    "          print(\"big eyes\", eyeA_ar)\n",
    "          #keyboard.press_and_release(\"command+shift+=\") # zoom in\n",
    "      else:\n",
    "        blinking = False\n",
    "\n",
    "      winkedL, winkedL_frames = timeout_double(winkedL, winkedL_frames)\n",
    "      winkedR, winkedR_frames = timeout_double(winkedR, winkedR_frames)\n",
    "      blink_count, blinking_frames = timeout_double(blink_count, blinking_frames)\n",
    "\n",
    "      mouth_inner_top = face[13]\n",
    "      mouth_inner_bottom = face[14]\n",
    "      mouth_inner_right = face[78]\n",
    "      mouth_inner_left = face[308]\n",
    "      mouth_inner_ar = get_aspect_ratio(\n",
    "        mouth_inner_top, mouth_inner_bottom, mouth_inner_right, mouth_inner_left)\n",
    "\n",
    "      nose_bottom = face[2]\n",
    "\n",
    "      mouth_open = mouth_inner_ar > MOUTH_OPEN_HEIGHT\n",
    "      if mouth_open:\n",
    "        print(\"mouth open\", mouth_inner_ar)\n",
    "        get_audio()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "\n",
    "\n",
    "      draw_frame(image, face_landmarks)\n",
    "      if RECORDING:\n",
    "        recording.write(image)\n",
    "\n",
    "    # Type 'q' on the video frame to quit\n",
    "    if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "      break\n",
    "\n",
    "if RECORDING:\n",
    "  recording.release()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hellosolid terminatorhellohello daminihello germanytom open my mouth hello 10 minut as wholeopen my mouth hello 10 minutes as moretubemateimageindian stick minutaudio system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)\n",
    "pyautogui.hotkey('command', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay(200)\n",
    "pyautogui.hotkey('command', 'v')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
